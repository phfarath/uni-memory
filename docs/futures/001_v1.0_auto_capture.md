# Auto-Capture Context

> **Versão Target:** V1.0
> **Status:** ⏳ Pendente
> **Owner:** Unassigned
> **Estimativa:** 80h

---

## Descrição

### Problema
Atualmente, usuários precisam **manualmente chamar `remember()`** para gravar memórias no sistema. Isso gera fricção significativa:
- Usuários esquecem de salvar contexto importante
- Decisões arquiteturais não são documentadas
- Erros encontrados e soluções aplicadas são perdidos
- Comandos executados (builds, testes, deploys) não ficam no histórico

**Exemplo do fluxo atual (manual):**
```
User: "Eu corrigi o bug no login mudando o timeout de 5s para 10s"
User: "remember: Bug no login corrigido aumentando timeout para 10s"
Claude: [usa tool remember] ✅ Memória gravada
```

**Problema:** Usuário precisa lembrar de chamar `remember()` - isso é um paradoxo!

### Solução
Implementar um sistema de **captura automática de contexto** que monitora atividades do sistema e grava memórias sem intervenção manual.

**Componentes principais:**
1. **Event Detectors** - Captura comandos, edits, erros, decisões
2. **Auto-Capture Engine** - Processa eventos e decide o que salvar
3. **Background Worker** - Persiste memórias de forma assíncrona
4. **MCP Tool** - Permite ativar/desativar auto-capture

**Exemplo do novo fluxo (automático):**
```
User: "Vou corrigir o bug no login"
[Sistema detecta: git commit -m "fix: timeout no login"]
[Auto-capture grava: "Commit fix: timeout no login - aumentou de 5s para 10s"]

User: "Qual foi a última correção que fiz?"
Claude: [busca memórias] "Você corrigiu o bug no login aumentando timeout para 10s"
```

### Valor
✅ **Reduz carga cognitiva** - Usuário não precisa lembrar de salvar contexto
✅ **Memórias mais ricas** - Captura 10x mais contexto que modo manual
✅ **Zero fricção** - Funciona em background sem interromper workflow
✅ **Diferencial competitivo** - Claude-Mem tem feature similar, precisamos ter também

**ROI Estimado:**
- Redução de 80% em chamadas manuais de `remember()`
- Aumento de 3x na quantidade de contexto capturado
- Melhoria de 50% na qualidade de recall

---

## Passos de Implementação

### 1. Código (50h)

#### 1.1 Database Schema (2h)
- [ ] **Criar tabela `auto_capture_events`** em `app/main.py:init_db()`
  ```sql
  CREATE TABLE IF NOT EXISTS auto_capture_events (
      id SERIAL PRIMARY KEY,
      api_key TEXT REFERENCES api_keys(key),
      session_id TEXT NOT NULL,
      event_type TEXT NOT NULL,  -- 'command', 'file_edit', 'error', 'decision'
      event_data JSONB NOT NULL,
      captured_at TIMESTAMPTZ DEFAULT NOW(),
      processed BOOLEAN DEFAULT FALSE,
      memory_id INTEGER REFERENCES memories(id)
  );
  ```

- [ ] **Criar índices de performance**
  ```sql
  CREATE INDEX IF NOT EXISTS idx_auto_capture_session
      ON auto_capture_events(session_id, captured_at DESC);

  CREATE INDEX IF NOT EXISTS idx_auto_capture_processed
      ON auto_capture_events(processed, captured_at);
  ```

#### 1.2 Auto-Capture Engine (25h)
- [ ] **Criar módulo `app/auto_capture.py`** com classe principal:
  ```python
  class AutoCaptureEngine:
      """
      Motor de captura automática de contexto.

      Responsável por:
      - Detectar eventos relevantes (comandos, edits, erros)
      - Decidir quais eventos merecem virar memórias
      - Processar eventos em background
      """

      def __init__(self):
          self.detectors = []
          self.enabled_sessions = {}  # {session_id: bool}

      def register_detector(self, detector: EventDetector):
          """Registra novo detector de eventos"""
          pass

      def process_event(self, event: dict) -> Optional[str]:
          """
          Processa evento e decide se deve criar memória.

          Returns:
              memory_content se evento é relevante, None caso contrário
          """
          pass

      def enable_for_session(self, session_id: str):
          """Ativa auto-capture para uma sessão"""
          pass

      def disable_for_session(self, session_id: str):
          """Desativa auto-capture para uma sessão"""
          pass
  ```

- [ ] **Implementar `CommandDetector`** - detecta comandos executados:
  ```python
  class CommandDetector:
      """Detecta comandos shell executados pelo usuário"""

      RELEVANT_COMMANDS = [
          'git commit', 'git push', 'git merge',
          'npm install', 'pip install',
          'pytest', 'npm test', 'cargo test',
          'docker build', 'docker run',
          'kubectl apply', 'terraform apply'
      ]

      def detect(self, event_data: dict) -> bool:
          """Retorna True se comando é relevante"""
          command = event_data.get('command', '')
          return any(cmd in command for cmd in self.RELEVANT_COMMANDS)

      def format_memory(self, event_data: dict) -> str:
          """Formata evento como texto de memória"""
          return f"Comando executado: {event_data['command']}"
  ```

- [ ] **Implementar `FileEditDetector`** - detecta edições de arquivos:
  ```python
  class FileEditDetector:
      """Detecta quando arquivos importantes são editados"""

      RELEVANT_EXTENSIONS = ['.py', '.js', '.ts', '.go', '.rs', '.java']
      IGNORE_PATTERNS = ['node_modules/', '__pycache__/', '.git/']

      def detect(self, event_data: dict) -> bool:
          """Retorna True se edit é relevante"""
          file_path = event_data.get('file_path', '')

          # Ignorar arquivos em diretórios irrelevantes
          if any(p in file_path for p in self.IGNORE_PATTERNS):
              return False

          # Aceitar apenas extensões relevantes
          return any(file_path.endswith(ext) for ext in self.RELEVANT_EXTENSIONS)

      def format_memory(self, event_data: dict) -> str:
          """Formata edit como memória com diff summary"""
          file_path = event_data['file_path']
          lines_added = event_data.get('lines_added', 0)
          lines_removed = event_data.get('lines_removed', 0)

          return f"Editado {file_path}: +{lines_added} -{lines_removed} linhas"
  ```

- [ ] **Implementar `ErrorDetector`** - detecta erros e soluções:
  ```python
  class ErrorDetector:
      """Detecta erros encontrados e como foram resolvidos"""

      ERROR_KEYWORDS = [
          'error:', 'exception:', 'traceback',
          'failed', 'fatal', 'segfault'
      ]

      def detect(self, event_data: dict) -> bool:
          """Retorna True se mensagem contém erro"""
          message = event_data.get('message', '').lower()
          return any(kw in message for kw in self.ERROR_KEYWORDS)

      def format_memory(self, event_data: dict) -> str:
          """Formata erro e solução como memória"""
          error_msg = event_data['message']
          solution = event_data.get('solution', 'Solução não documentada')

          return f"Erro encontrado: {error_msg}\nSolução: {solution}"
  ```

- [ ] **Implementar `DecisionDetector`** - detecta decisões arquiteturais:
  ```python
  class DecisionDetector:
      """Detecta quando usuário toma decisões arquiteturais importantes"""

      DECISION_KEYWORDS = [
          'vou usar', 'decidimos usar', 'escolhemos',
          'arquitetura', 'padrão de design', 'estratégia',
          'migrar para', 'trocar para'
      ]

      def detect(self, event_data: dict) -> bool:
          """Retorna True se mensagem contém decisão"""
          message = event_data.get('message', '').lower()
          return any(kw in message for kw in self.DECISION_KEYWORDS)

      def format_memory(self, event_data: dict) -> str:
          """Formata decisão como memória"""
          return f"Decisão arquitetural: {event_data['message']}"
  ```

#### 1.3 REST API Endpoints (8h)
- [ ] **Adicionar endpoint `POST /v1/auto-capture/enable`** em `app/main.py`:
  ```python
  @app.post("/v1/auto-capture/enable")
  async def enable_auto_capture(
      session_id: str,
      user: dict = Security(verify_api_key)
  ):
      """
      Ativa auto-capture para uma sessão específica.

      Body:
          {"session_id": "user-session-123"}

      Returns:
          {"status": "enabled", "session_id": "..."}
      """
      engine.enable_for_session(session_id)
      return {"status": "enabled", "session_id": session_id}
  ```

- [ ] **Adicionar endpoint `POST /v1/auto-capture/disable`**:
  ```python
  @app.post("/v1/auto-capture/disable")
  async def disable_auto_capture(
      session_id: str,
      user: dict = Security(verify_api_key)
  ):
      """Desativa auto-capture para uma sessão"""
      engine.disable_for_session(session_id)
      return {"status": "disabled", "session_id": session_id}
  ```

- [ ] **Adicionar endpoint `GET /v1/auto-capture/status`**:
  ```python
  @app.get("/v1/auto-capture/status")
  async def get_auto_capture_status(
      session_id: str,
      user: dict = Security(verify_api_key)
  ):
      """Retorna status de auto-capture para sessão"""
      is_enabled = engine.is_enabled(session_id)

      conn = get_db_connection()
      c = conn.cursor()
      c.execute("""
          SELECT COUNT(*) as total,
                 COUNT(CASE WHEN processed THEN 1 END) as processed
          FROM auto_capture_events
          WHERE session_id = %s
      """, (session_id,))
      stats = c.fetchone()
      conn.close()

      return {
          "session_id": session_id,
          "enabled": is_enabled,
          "total_events": stats[0],
          "processed_events": stats[1]
      }
  ```

#### 1.4 MCP Tools (5h)
- [ ] **Adicionar MCP tool `enable_auto_capture`** em `app/main.py:list_tools()`:
  ```python
  Tool(
      name="enable_auto_capture",
      description="Ativa captura automática de contexto para a sessão atual",
      inputSchema={
          "type": "object",
          "properties": {
              "session_id": {
                  "type": "string",
                  "description": "ID da sessão para ativar auto-capture"
              }
          },
          "required": ["session_id"]
      }
  )
  ```

- [ ] **Implementar handler no `call_tool()`**:
  ```python
  elif name == "enable_auto_capture":
      session_id = arguments["session_id"]
      engine.enable_for_session(session_id)
      return [TextContent(
          type="text",
          text=f"✅ Auto-capture ativado para sessão '{session_id}'"
      )]
  ```

- [ ] **Adicionar MCP tool `disable_auto_capture`** e handler correspondente

#### 1.5 Background Worker (8h)
- [ ] **Criar worker em `app/auto_capture.py`**:
  ```python
  import schedule
  import time

  def process_pending_events():
      """
      Processa eventos pendentes e cria memórias.
      Executado a cada 30 segundos.
      """
      conn = get_db_connection()
      c = conn.cursor()

      # Buscar eventos não processados
      c.execute("""
          SELECT id, api_key, session_id, event_type, event_data
          FROM auto_capture_events
          WHERE processed = FALSE
          ORDER BY captured_at ASC
          LIMIT 100
      """)

      events = c.fetchall()

      for event in events:
          event_id, api_key, session_id, event_type, event_data = event

          # Processar evento
          memory_content = engine.process_event({
              'type': event_type,
              'data': event_data
          })

          if memory_content:
              # Criar memória
              add_memory_trace_logic(session_id, 'system', memory_content)

              # Marcar como processado
              c.execute("""
                  UPDATE auto_capture_events
                  SET processed = TRUE
                  WHERE id = %s
              """, (event_id,))

      conn.commit()
      conn.close()

      logger.info(f"[AUTO_CAPTURE] Processados {len(events)} eventos")

  # Agendar worker
  schedule.every(30).seconds.do(process_pending_events)
  ```

- [ ] **Integrar worker no startup da aplicação** em `app/main.py`:
  ```python
  @app.on_event("startup")
  async def startup_event():
      init_db()

      # Iniciar background worker de auto-capture
      import threading
      def run_schedule():
          while True:
              schedule.run_pending()
              time.sleep(1)

      thread = threading.Thread(target=run_schedule, daemon=True)
      thread.start()
      logger.info("[AUTO_CAPTURE] Background worker iniciado")
  ```

#### 1.6 Rate Limiting (2h)
- [ ] **Adicionar action type em `app/rate_limiter.py`**:
  ```python
  ACTION_AUTO_CAPTURE = "auto_capture"

  ENDPOINT_ACTIONS = {
      # ... existing mappings
      "/v1/auto-capture/enable": ACTION_AUTO_CAPTURE,
      "/v1/auto-capture/disable": ACTION_AUTO_CAPTURE,
      "/v1/auto-capture/status": ACTION_REQUEST,
  }
  ```

- [ ] **Atualizar `tier_definitions` para incluir limite de auto-capture**:
  ```sql
  ALTER TABLE tier_definitions
  ADD COLUMN max_auto_capture_per_day INTEGER DEFAULT 1000;

  -- Configurar limites por tier
  UPDATE tier_definitions SET max_auto_capture_per_day = 100 WHERE tier = 'free';
  UPDATE tier_definitions SET max_auto_capture_per_day = 5000 WHERE tier = 'pro';
  UPDATE tier_definitions SET max_auto_capture_per_day = 50000 WHERE tier = 'team';
  UPDATE tier_definitions SET max_auto_capture_per_day = -1 WHERE tier = 'root';
  ```

---

### 2. Testes (15h)

- [ ] **Criar `tests/test_auto_capture.py`** com test suite completa

- [ ] **Test: Ativação de auto-capture via MCP tool**
  ```python
  def test_enable_auto_capture_mcp():
      response = client.post("/mcp", json={
          "method": "tools/call",
          "params": {
              "name": "enable_auto_capture",
              "arguments": {"session_id": "test-session"}
          }
      }, headers={"x-api-key": API_KEY})

      assert response.status_code == 200
      assert "ativado" in response.json()["content"][0]["text"]
  ```

- [ ] **Test: Captura de comando executado**
  ```python
  def test_command_detection():
      detector = CommandDetector()

      # Comando relevante
      assert detector.detect({"command": "git commit -m 'test'"})

      # Comando irrelevante
      assert not detector.detect({"command": "ls -la"})
  ```

- [ ] **Test: Captura de file edit com diff**
  ```python
  def test_file_edit_detection():
      detector = FileEditDetector()

      # Arquivo relevante
      assert detector.detect({
          "file_path": "app/main.py",
          "lines_added": 10,
          "lines_removed": 5
      })

      # Arquivo em node_modules (ignorar)
      assert not detector.detect({
          "file_path": "node_modules/package/index.js"
      })
  ```

- [ ] **Test: Detecção de erro e logging**
  ```python
  def test_error_detection():
      detector = ErrorDetector()

      assert detector.detect({
          "message": "Error: Connection timeout"
      })

      memory = detector.format_memory({
          "message": "Error: 500",
          "solution": "Aumentado timeout"
      })

      assert "Erro encontrado" in memory
      assert "Solução" in memory
  ```

- [ ] **Test: Rate limit para auto-capture**
  ```python
  def test_auto_capture_rate_limit():
      # Simular muitos eventos
      for i in range(150):  # free tier: 100/day
          response = client.post("/v1/auto-capture/event",
              json={"event_type": "command", "data": {}},
              headers={"x-api-key": FREE_API_KEY})

      # Última request deve ser bloqueada
      assert response.status_code == 429
  ```

- [ ] **Test: Desativação de auto-capture**
  ```python
  def test_disable_auto_capture():
      # Ativar
      client.post("/v1/auto-capture/enable",
          json={"session_id": "test"},
          headers={"x-api-key": API_KEY})

      # Desativar
      response = client.post("/v1/auto-capture/disable",
          json={"session_id": "test"},
          headers={"x-api-key": API_KEY})

      assert response.json()["status"] == "disabled"
  ```

- [ ] **Test: Background worker processa eventos**
  ```python
  def test_background_worker_processing():
      # Inserir evento pendente
      conn = get_db_connection()
      c = conn.cursor()
      c.execute("""
          INSERT INTO auto_capture_events
          (session_id, event_type, event_data, processed)
          VALUES ('test', 'command', '{"command": "git commit"}', FALSE)
      """)
      conn.commit()

      # Executar worker
      process_pending_events()

      # Verificar que foi processado
      c.execute("SELECT processed FROM auto_capture_events WHERE session_id='test'")
      assert c.fetchone()[0] == True
      conn.close()
  ```

---

### 3. Documentação (10h)

- [ ] **Atualizar `ARCHITECTURE.md`**: Adicionar seção "Auto-Capture Architecture" com diagrama Mermaid:
  ```mermaid
  graph TD
      A[User Activity] --> B{Event Detectors}
      B --> C[CommandDetector]
      B --> D[FileEditDetector]
      B --> E[ErrorDetector]
      B --> F[DecisionDetector]

      C --> G[AutoCaptureEngine]
      D --> G
      E --> G
      F --> G

      G --> H{Relevant?}
      H -->|Yes| I[auto_capture_events table]
      H -->|No| J[Discard]

      I --> K[Background Worker]
      K --> L[add_memory_trace_logic]
      L --> M[memories table]
  ```

- [ ] **Atualizar `AI_INSTRUCTIONS.md`**: Adicionar template para novos event detectors:
  ```markdown
  ## Como Adicionar Novo Event Detector

  1. Criar classe em `app/auto_capture.py`:
     - Herdar de `EventDetector` (interface base)
     - Implementar `detect(event_data: dict) -> bool`
     - Implementar `format_memory(event_data: dict) -> str`

  2. Registrar detector no `AutoCaptureEngine`:
     engine.register_detector(MyNewDetector())

  3. Adicionar testes em `tests/test_auto_capture.py`
  ```

- [ ] **Atualizar `app/README.md`**: Documentar AutoCaptureEngine API
  ```markdown
  ### AutoCaptureEngine

  Motor responsável por captura automática de contexto.

  **Usage:**
  python
  from app.auto_capture import AutoCaptureEngine

  engine = AutoCaptureEngine()
  engine.enable_for_session("user-session-123")

  # Processar evento
  memory = engine.process_event({
      'type': 'command',
      'data': {'command': 'git commit -m "fix bug"'}
  })


  **Event Types:**
  - `command`: Comandos shell executados
  - `file_edit`: Arquivos editados
  - `error`: Erros encontrados
  - `decision`: Decisões arquiteturais
  ```

- [ ] **Atualizar `INLINE_DOCS.md`**: Adicionar docstring para `AutoCaptureEngine.process_event()`

---

### 4. Infraestrutura (5h)

- [ ] **Criar migration script `migrations/001_auto_capture.sql`**:
  ```sql
  -- Migration: Auto-Capture Events Table
  -- Date: 2026-02-03

  CREATE TABLE IF NOT EXISTS auto_capture_events (
      id SERIAL PRIMARY KEY,
      api_key TEXT REFERENCES api_keys(key),
      session_id TEXT NOT NULL,
      event_type TEXT NOT NULL,
      event_data JSONB NOT NULL,
      captured_at TIMESTAMPTZ DEFAULT NOW(),
      processed BOOLEAN DEFAULT FALSE,
      memory_id INTEGER REFERENCES memories(id)
  );

  CREATE INDEX idx_auto_capture_session
      ON auto_capture_events(session_id, captured_at DESC);

  CREATE INDEX idx_auto_capture_processed
      ON auto_capture_events(processed, captured_at);

  ALTER TABLE tier_definitions
      ADD COLUMN IF NOT EXISTS max_auto_capture_per_day INTEGER DEFAULT 1000;

  UPDATE tier_definitions SET max_auto_capture_per_day = 100 WHERE tier = 'free';
  UPDATE tier_definitions SET max_auto_capture_per_day = 5000 WHERE tier = 'pro';
  UPDATE tier_definitions SET max_auto_capture_per_day = 50000 WHERE tier = 'team';
  UPDATE tier_definitions SET max_auto_capture_per_day = -1 WHERE tier = 'root';
  ```

- [ ] **Configurar schedule library** em `requirements.txt`:
  ```
  schedule==1.2.0
  ```

- [ ] **Adicionar configuração de cleanup job** para eventos antigos (> 30 dias):
  ```python
  def cleanup_old_auto_capture_events():
      """Remove eventos processados com mais de 30 dias"""
      conn = get_db_connection()
      c = conn.cursor()

      c.execute("""
          DELETE FROM auto_capture_events
          WHERE processed = TRUE
          AND captured_at < NOW() - INTERVAL '30 days'
      """)

      deleted = c.rowcount
      conn.commit()
      conn.close()

      logger.info(f"[AUTO_CAPTURE] Cleanup: {deleted} eventos antigos removidos")

  # Executar semanalmente
  schedule.every().week.do(cleanup_old_auto_capture_events)
  ```

---

## Dependências

**Nenhuma** - Esta feature pode ser implementada de forma completamente independente.

---

## Referências

- [Claude-Mem Auto Context](https://github.com/thedotmack/claude-mem) - Inspiração para captura automática
- [MCP Memory Service](https://github.com/doobidoo/mcp-memory-service) - Best practices de memory triggers
- [Python Schedule](https://schedule.readthedocs.io/) - Background job scheduling
- [JSONB PostgreSQL](https://www.postgresql.org/docs/current/datatype-json.html) - Armazenamento de event_data

---

## Notas de Implementação

### Segurança
- ⚠️ Nunca capturar dados sensíveis (passwords, tokens, secrets)
- ✅ Adicionar filtro para keywords sensíveis (API_KEY, PASSWORD, SECRET)
- ✅ Rate limiting obrigatório para prevenir spam

### Performance
- Background worker deve processar em batches (100 eventos por vez)
- Índices são críticos para queries de eventos pendentes
- Considerar particionamento da tabela `auto_capture_events` se volume > 1M registros

### Monitoramento
- Logar quantos eventos são processados por minuto
- Alertar se fila de eventos pendentes > 1000
- Métricas: eventos capturados, eventos processados, eventos descartados

---

**Versão do documento:** 1.0
**Última atualização:** 2026-02-03
