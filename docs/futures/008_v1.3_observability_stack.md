# Observability Stack

> **Versão Target:** V1.3
> **Status:** ⏳ Pendente
> **Owner:** Unassigned
> **Estimativa:** 40h

---

## Descrição

### Problema
Logs atuais são básicos (`logger.info()`):
- Sem traces distribuídos
- Difícil debugar latência em produção
- Sem métricas estruturadas (error rate, p95, p99)
- Alerting manual

**Exemplo:**
```
[INFO] Memory trace saved
→ Quanto tempo levou? Qual endpoint? Qual usuário?
→ Informação insuficiente para debugging
```

### Solução
Integrar **OpenTelemetry** para observabilidade completa:

**Componentes:**
1. **Traces** - Latência distribuída de cada request
2. **Metrics** - Error rate, throughput, p95/p99
3. **Logs** - Structured logging com contexto
4. **Exporters** - Grafana, Datadog, ou Jaeger

**Fluxo:**
```
Request → FastAPI
    ↓
[OpenTelemetry Middleware]
    ↓
Auto-trace de todo o flow
    ↓
Export para Grafana/Datadog
    ↓
Dashboards e alertas
```

### Valor
✅ **Debugging 10x mais rápido** - Traces mostram exatamente onde está lento
✅ **Proativo** - Alertas automáticos em erros/latência
✅ **Dashboards** - Visualização de performance em real-time

---

## Passos de Implementação

### 1. Código (25h)
- [ ] Instalar dependências:
  ```bash
  pip install opentelemetry-api opentelemetry-sdk
  pip install opentelemetry-instrumentation-fastapi
  pip install opentelemetry-exporter-otlp
  ```

- [ ] Configurar tracer em `app/main.py`:
  ```python
  from opentelemetry import trace
  from opentelemetry.sdk.trace import TracerProvider
  from opentelemetry.sdk.trace.export import BatchSpanProcessor
  from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter

  # Setup provider
  trace.set_tracer_provider(TracerProvider())
  tracer = trace.get_tracer(__name__)

  # Setup exporter (Grafana/Datadog)
  otlp_exporter = OTLPSpanExporter(endpoint="http://localhost:4317")
  span_processor = BatchSpanProcessor(otlp_exporter)
  trace.get_tracer_provider().add_span_processor(span_processor)
  ```

- [ ] Instrumentar FastAPI automaticamente:
  ```python
  from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor

  FastAPIInstrumentor.instrument_app(app)
  ```

- [ ] Adicionar custom spans em funções críticas:
  ```python
  @app.get("/v1/memories")
  async def list_memories(...):
      with tracer.start_as_current_span("list_memories"):
          # Auto-trace de latência, errors
          ...
  ```

- [ ] Custom metrics:
  ```python
  from opentelemetry import metrics

  meter = metrics.get_meter(__name__)
  request_counter = meter.create_counter("requests_total")
  error_counter = meter.create_counter("errors_total")
  ```

### 2. Testes (8h)
- [ ] Test: Traces são exportados corretamente
- [ ] Test: Custom metrics incrementam
- [ ] Test: Error tracking funciona

### 3. Documentação (5h)
- [ ] Guia de setup Grafana/Datadog
- [ ] Dashboards recomendados

### 4. Infraestrutura (2h)
- [ ] Setup Grafana + Tempo (ou Datadog)
- [ ] Criar dashboards padrão

---

## Dependências
Nenhuma

---

## Referências
- [OpenTelemetry Docs](https://opentelemetry.io/docs/)
- [FastAPI + OpenTelemetry](https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/fastapi/fastapi.html)

---

**Versão do documento:** 1.0
**Última atualização:** 2026-02-03
