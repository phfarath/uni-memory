# Duplicate Prevention - Plano de ImplementaÃ§Ã£o

**Feature**: Duplicate Prevention (PrevenÃ§Ã£o de Duplicatas)
**Spec**: `docs/futures/005_v1.0_duplicate_prevention.md`
**Status**: ğŸ”„ Em Progress
**Date**: 2026-02-10
**Branch**: `claude/plan-duplicate-prevention-J2ZJ1`

---

## Overview

Implementar verificaÃ§Ã£o de similaridade semÃ¢ntica antes de gravar novas memÃ³rias, evitando duplicatas no banco de dados. Quando uma memÃ³ria com similaridade >= 0.95 jÃ¡ existir, o sistema retorna aviso e oferece opÃ§Ã£o de merge (atualizar timestamp) ou force override.

---

## AnÃ¡lise do Estado Atual

### Pontos de Entrada para GravaÃ§Ã£o de MemÃ³rias

Existem **4 caminhos** pelos quais uma memÃ³ria Ã© inserida no banco:

1. **`add_memory_trace_logic()`** (`app/main.py:367`) - FunÃ§Ã£o sÃ­ncrona core de persistÃªncia
2. **MCP Tool `remember`** (`app/main.py:561-570`) - Chama `add_memory_trace_logic()` diretamente
3. **REST `POST /v1/chat/completions`** (`app/main.py:1029-1040`) - Chama `add_memory_trace()` (wrapper async)
4. **Auto-Capture Worker** (`app/auto_capture.py:354-355`) - Chama `add_memory_trace_logic()` via scheduler

**DecisÃ£o arquitetural**: A verificaÃ§Ã£o de duplicatas deve ser implementada na camada mais baixa (`add_memory_trace_logic`) para cobrir TODOS os caminhos de escrita, mas como mÃ³dulo separado (`app/duplicate_prevention.py`) seguindo o padrÃ£o do `app/auto_capture.py`.

### Modelo de Dados Relevante

```sql
-- Tabela memories (existente)
CREATE TABLE memories (
    id SERIAL PRIMARY KEY,
    owner_key TEXT NOT NULL,
    workspace TEXT DEFAULT 'default',
    session_id TEXT NOT NULL,
    role TEXT NOT NULL,
    content TEXT NOT NULL,
    timestamp REAL,
    embedding vector(384)
);

-- Ãndices existentes
idx_memories_owner ON memories(owner_key)
idx_memories_workspace ON memories(owner_key, workspace)
```

### Operador de DistÃ¢ncia pgvector

O pgvector usa o operador `<=>` para **cosine distance** (nÃ£o cosine similarity):
- `distance = 1 - similarity`
- `similarity = 1 - distance`
- Threshold 0.95 similarity = distance <= 0.05

---

## Passos de ImplementaÃ§Ã£o

### Passo 1: Criar MÃ³dulo `app/duplicate_prevention.py`

**Arquivo**: `app/duplicate_prevention.py` (NOVO)

Criar mÃ³dulo dedicado seguindo o padrÃ£o de `app/auto_capture.py`:

```python
"""
Aethera Cortex Duplicate Prevention Module.
Semantic similarity check before memory persistence to prevent duplicate entries.
"""

import logging
from typing import Optional, Dict, Tuple

logger = logging.getLogger("Aethera.DuplicatePrevention")

# Default similarity threshold (0.95 = 95% similar)
DEFAULT_SIMILARITY_THRESHOLD = 0.95


class DuplicateCheckResult:
    """Result of a duplicate check operation."""

    def __init__(self, is_duplicate: bool, existing_id: Optional[int] = None,
                 existing_content: Optional[str] = None, similarity: float = 0.0):
        self.is_duplicate = is_duplicate
        self.existing_id = existing_id
        self.existing_content = existing_content
        self.similarity = similarity

    def to_dict(self) -> dict:
        return {
            "is_duplicate": self.is_duplicate,
            "existing_id": self.existing_id,
            "existing_content": self.existing_content,
            "similarity": round(self.similarity, 4)
        }


def check_duplicate(embedding: list, owner_key: str, session_id: str,
                    get_db_connection_func, threshold: float = DEFAULT_SIMILARITY_THRESHOLD
                    ) -> DuplicateCheckResult:
    """
    Verifica se jÃ¡ existe uma memÃ³ria semanticamente similar no banco.

    Args:
        embedding: Vetor de embedding jÃ¡ calculado (384-dim)
        owner_key: Chave do dono (multi-tenancy filter)
        session_id: ID da sessÃ£o (escopo de busca)
        get_db_connection_func: FunÃ§Ã£o para obter conexÃ£o com DB
        threshold: Limiar de similaridade (default: 0.95)

    Returns:
        DuplicateCheckResult com is_duplicate, existing_id, similarity

    Algorithm:
        1. Busca a memÃ³ria mais similar via pgvector cosine distance
        2. Filtra por owner_key (multi-tenancy)
        3. Converte distance para similarity (1 - distance)
        4. Retorna duplicate=True se similarity >= threshold
    """
    try:
        conn = get_db_connection_func()
        c = conn.cursor()

        c.execute("""
            SELECT id, content, (embedding <=> %s::vector) as distance
            FROM memories
            WHERE owner_key = %s
            ORDER BY distance ASC
            LIMIT 1
        """, (embedding, owner_key))

        result = c.fetchone()
        conn.close()

        if not result:
            return DuplicateCheckResult(is_duplicate=False)

        existing_id, existing_content, distance = result
        similarity = 1.0 - distance

        if similarity >= threshold:
            logger.info(
                f"[DUPLICATE] Detected: similarity={similarity:.4f} "
                f"(threshold={threshold}) | memory_id={existing_id} | "
                f"owner={owner_key[:20]}..."
            )
            return DuplicateCheckResult(
                is_duplicate=True,
                existing_id=existing_id,
                existing_content=existing_content,
                similarity=similarity
            )

        return DuplicateCheckResult(is_duplicate=False, similarity=similarity)

    except Exception as e:
        logger.error(f"[DUPLICATE] Check failed: {e}")
        # Em caso de erro, permitir gravaÃ§Ã£o (fail-open)
        return DuplicateCheckResult(is_duplicate=False)


def merge_memory(existing_id: int, owner_key: str, get_db_connection_func) -> bool:
    """
    Atualiza o timestamp de uma memÃ³ria existente (merge strategy).

    Em vez de criar duplicata, atualiza o timestamp da memÃ³ria existente
    para refletir que o usuÃ¡rio referenciou essa informaÃ§Ã£o novamente.

    Args:
        existing_id: ID da memÃ³ria existente
        owner_key: Chave do dono (verificaÃ§Ã£o de ownership)
        get_db_connection_func: FunÃ§Ã£o para obter conexÃ£o com DB

    Returns:
        True se merge foi realizado, False caso contrÃ¡rio
    """
    import time
    try:
        conn = get_db_connection_func()
        c = conn.cursor()
        c.execute(
            "UPDATE memories SET timestamp = %s WHERE id = %s AND owner_key = %s",
            (time.time(), existing_id, owner_key)
        )
        updated = c.rowcount
        conn.commit()
        conn.close()

        if updated > 0:
            logger.info(f"[DUPLICATE] Merged: memory_id={existing_id} timestamp updated")
            return True
        return False

    except Exception as e:
        logger.error(f"[DUPLICATE] Merge failed: {e}")
        return False
```

**Componentes**:
- `DuplicateCheckResult` - Dataclass para resultado da verificaÃ§Ã£o
- `check_duplicate()` - FunÃ§Ã£o pura que verifica duplicatas via pgvector
- `merge_memory()` - FunÃ§Ã£o para atualizar timestamp de memÃ³ria existente (merge strategy)

**DecisÃµes de design**:
- A funÃ§Ã£o recebe o `embedding` jÃ¡ calculado (evita recomputar)
- Busca por `owner_key` (respeita multi-tenancy), sem filtrar por `session_id` (duplicatas cross-session)
- Fail-open: em caso de erro no check, permite a gravaÃ§Ã£o normalmente
- Threshold configurÃ¡vel com default 0.95

---

### Passo 2: Modificar `add_memory_trace_logic()` em `app/main.py`

**Arquivo**: `app/main.py` (MODIFICAR)

Integrar a verificaÃ§Ã£o de duplicatas na funÃ§Ã£o core de persistÃªncia:

```python
# Novo import no topo do arquivo (apÃ³s linha 28)
from app.duplicate_prevention import check_duplicate, merge_memory

# Modificar add_memory_trace_logic (linha 367)
def add_memory_trace_logic(owner_key: str, session_id: str, role: str, content: str,
                           workspace: str = "default", force: bool = False):
    """FunÃ§Ã£o sÃ­ncrona/lÃ³gica pura para persistÃªncia. Inclui owner_key para multi-tenancy e prevenÃ§Ã£o de duplicatas."""
    try:
        # VetorizaÃ§Ã£o
        vec = embed_model.encode([content])[0].tolist()

        # Duplicate check (skip if force=True)
        if not force:
            dup_result = check_duplicate(vec, owner_key, session_id, get_db_connection)
            if dup_result.is_duplicate:
                # Merge: atualizar timestamp da memÃ³ria existente
                merge_memory(dup_result.existing_id, owner_key, get_db_connection)
                logger.info(
                    f"DEBUG [MEMORY] Duplicata detectada (similarity={dup_result.similarity:.4f}). "
                    f"Merge realizado com memory_id={dup_result.existing_id}."
                )
                return {"action": "merged", "existing_id": dup_result.existing_id,
                        "similarity": dup_result.similarity}

        conn = get_db_connection()
        c = conn.cursor()
        c.execute("""INSERT INTO memories (owner_key, workspace, session_id, role, content, timestamp, embedding)
                     VALUES (%s, %s, %s, %s, %s, %s, %s)""",
                  (owner_key, workspace, session_id, role, content, time.time(), vec))
        conn.commit()
        conn.close()
        logger.info(f"DEBUG [MEMORY] Trace persistido para owner {owner_key[:20]}...")
        return {"action": "created"}
    except Exception as e:
        logger.error(f"CRITICAL [MEMORY] Falha ao gravar no Postgres: {e}")
        raise e
```

**MudanÃ§as**:
1. Adicionar parÃ¢metro `force: bool = False`
2. Antes do INSERT, chamar `check_duplicate()` com o embedding jÃ¡ calculado
3. Se duplicata encontrada e `force=False`: fazer merge (update timestamp) e retornar early
4. Se `force=True`: pular verificaÃ§Ã£o e inserir normalmente
5. Retornar dict com `action` para informar o chamador sobre o resultado

**Importante**: O embedding Ã© calculado UMA VEZ e reutilizado tanto para o check quanto para o INSERT. Sem custo adicional de CPU para a verificaÃ§Ã£o.

---

### Passo 3: Atualizar MCP Tool `remember` com parÃ¢metro `force`

**Arquivo**: `app/main.py` (MODIFICAR)

#### 3a. Atualizar schema da tool `remember` (na funÃ§Ã£o `list_tools`)

Adicionar parÃ¢metro `force` ao inputSchema da tool `remember`:

```python
Tool(
    name="remember",
    description="Grava uma informaÃ§Ã£o importante na memÃ³ria de longo prazo. Detecta duplicatas automaticamente.",
    inputSchema={
        "type": "object",
        "properties": {
            "fact": {"type": "string", "description": "O conteÃºdo exato a ser lembrado."},
            "category": {"type": "string", "description": "Tag para organizaÃ§Ã£o (ex: 'work', 'code'). Default: 'general'"},
            "force": {"type": "boolean", "description": "Se True, grava mesmo que duplicata exista. Default: false"}
        },
        "required": ["fact"]
    }
)
```

#### 3b. Atualizar handler da tool `remember` (na funÃ§Ã£o `call_tool`)

```python
if name == "remember":
    fact = arguments.get("fact")
    category = arguments.get("category", "general")
    workspace = arguments.get("workspace", "default")
    force = arguments.get("force", False)
    try:
        enriched = f"[{category.upper()}] {fact}"
        result = add_memory_trace_logic(owner_key, "mcp-session", "user", enriched, workspace, force=force)

        if result and result.get("action") == "merged":
            return [TextContent(
                type="text",
                text=f"MemÃ³ria similar jÃ¡ existe (similaridade: {result['similarity']:.1%}). "
                     f"Timestamp atualizado na memÃ³ria existente (ID: {result['existing_id']}). "
                     f"Use force=true para gravar mesmo assim."
            )]

        return [TextContent(type="text", text="MemÃ³ria salva com sucesso na Nuvem Aethera.")]
    except Exception as e:
        return [TextContent(type="text", text=f"Erro interno: {e}")]
```

---

### Passo 4: Adicionar Endpoint REST `POST /v1/memories/check-duplicate`

**Arquivo**: `app/main.py` (MODIFICAR)

Novo endpoint para UI/API verificar duplicatas antes de gravar:

```python
class DuplicateCheckRequest(BaseModel):
    content: str
    session_id: str = "default"

@app.post("/v1/memories/check-duplicate", tags=["Core"])
async def check_memory_duplicate(req: DuplicateCheckRequest, user: dict = Security(verify_api_key)):
    """Verifica se uma memÃ³ria similar jÃ¡ existe antes de gravar."""
    owner_key = user["key"]

    # Gerar embedding
    vec = embed_model.encode([req.content])[0].tolist()

    # Verificar duplicata
    result = check_duplicate(vec, owner_key, req.session_id, get_db_connection)

    return {
        "is_duplicate": result.is_duplicate,
        "existing_id": result.existing_id,
        "existing_content": result.existing_content,
        "similarity": round(result.similarity, 4) if result.similarity > 0 else 0
    }
```

---

### Passo 5: Adicionar Ãndice para Performance de Busca de Duplicatas

**Arquivo**: `app/main.py` (MODIFICAR - em `init_db()`)

Adicionar Ã­ndice IVFFlat para acelerar buscas vetoriais de duplicatas:

```python
# ApÃ³s os Ã­ndices existentes de memories (apÃ³s linha 111)
# 2c. Vector similarity index for duplicate detection
c.execute("""
    DO $$ BEGIN
        IF NOT EXISTS (
            SELECT 1 FROM pg_indexes WHERE indexname = 'idx_memories_embedding_ivfflat'
        ) THEN
            -- Only create IVFFlat index if there are enough rows (pgvector requires lists < nrows)
            IF (SELECT COUNT(*) FROM memories) >= 100 THEN
                CREATE INDEX idx_memories_embedding_ivfflat
                ON memories USING ivfflat (embedding vector_cosine_ops) WITH (lists = 50);
            END IF;
        END IF;
    END $$;
""")
```

**Nota**: O Ã­ndice IVFFlat requer um mÃ­nimo de linhas para ser criado. Para bancos pequenos, o sequential scan Ã© adequado. O Ã­ndice serÃ¡ criado condicionalmente quando houver >= 100 memÃ³rias.

Alternativa mais simples (sem condiÃ§Ã£o):
```python
# HNSW index - funciona com qualquer nÃºmero de linhas
c.execute("""
    CREATE INDEX IF NOT EXISTS idx_memories_embedding_hnsw
    ON memories USING hnsw (embedding vector_cosine_ops)
""")
```

**DecisÃ£o**: Usar HNSW pois nÃ£o tem restriÃ§Ã£o de mÃ­nimo de linhas e tem melhor recall.

---

### Passo 6: Atualizar Rate Limiter

**Arquivo**: `app/rate_limiter.py` (MODIFICAR)

Adicionar mapeamento do novo endpoint:

```python
# Em ENDPOINT_ACTIONS, adicionar:
"POST /v1/memories/check-duplicate": (ACTION_EMBEDDING, 1),
```

O check-duplicate consome um embedding, entÃ£o Ã© categorizado como `ACTION_EMBEDDING`.

---

### Passo 7: Criar Migration Script

**Arquivo**: `migrations/002_duplicate_prevention.sql` (NOVO)

```sql
-- Migration: Duplicate Prevention
-- Date: 2026-02-10
-- Description: Adds vector index for efficient duplicate detection

-- 1. Create HNSW vector index for cosine similarity searches
CREATE INDEX IF NOT EXISTS idx_memories_embedding_hnsw
    ON memories USING hnsw (embedding vector_cosine_ops);

-- Rollback script (run manually if needed):
-- DROP INDEX IF EXISTS idx_memories_embedding_hnsw;
```

---

### Passo 8: Criar Test Suite

**Arquivo**: `tests/test_duplicate_prevention.py` (NOVO)

Seguindo o padrÃ£o exato de `tests/test_auto_capture.py`:

| # | Test | Tipo | DescriÃ§Ã£o |
|---|------|------|-----------|
| 1 | `test_check_duplicate_endpoint` | Integration | POST `/v1/memories/check-duplicate` retorna `is_duplicate=false` para conteÃºdo novo |
| 2 | `test_detect_exact_duplicate` | Integration | Salva memÃ³ria, verifica check retorna `is_duplicate=true` com similarity ~1.0 |
| 3 | `test_detect_similar_duplicate` | Integration | Salva "Meu cafÃ© favorito Ã© cappuccino", verifica com "Meu cafÃ© preferido Ã© cappuccino" |
| 4 | `test_no_block_different_memory` | Integration | ConteÃºdos diferentes nÃ£o sÃ£o marcados como duplicata |
| 5 | `test_remember_auto_merge` | Integration | MCP `remember` detecta duplicata e faz merge (retorna mensagem de similaridade) |
| 6 | `test_remember_force_override` | Integration | MCP `remember` com `force=true` grava mesmo com duplicata |
| 7 | `test_merge_updates_timestamp` | Integration | Verificar que merge atualiza timestamp da memÃ³ria existente |
| 8 | `test_check_duplicate_unit` | Unit | Testar `check_duplicate()` isoladamente |
| 9 | `test_merge_memory_unit` | Unit | Testar `merge_memory()` isoladamente |
| 10 | `test_cross_session_duplicate` | Integration | Duplicata detectada entre sessÃµes diferentes do mesmo owner |

```python
"""
Test suite for Duplicate Prevention functionality.
Run: python tests/test_duplicate_prevention.py

Requires: Server running at localhost:8001
"""

import requests
import time
import sys
import os

BASE_URL = "http://localhost:8001"
ROOT_KEY = None

def get_root_key():
    if ROOT_KEY:
        return ROOT_KEY
    key = os.environ.get("AETHERA_ROOT_KEY") or os.environ.get("ROOT_KEY")
    if not key:
        print("Please set AETHERA_ROOT_KEY environment variable.")
        sys.exit(1)
    return key

def create_test_key(root_key, tier="free"):
    resp = requests.post(
        f"{BASE_URL}/admin/keys/create",
        headers={"x-api-key": root_key, "Content-Type": "application/json"},
        json={"owner_name": f"dup-test-{tier}", "tier": tier},
        timeout=5
    )
    if resp.status_code != 200:
        raise Exception(f"Failed to create test key: {resp.text}")
    return resp.json()["key"]

def revoke_test_key(root_key, test_key):
    requests.post(
        f"{BASE_URL}/admin/keys/revoke",
        headers={"x-api-key": root_key, "Content-Type": "application/json"},
        params={"target_key": test_key},
        timeout=5
    )

# ... (tests seguem padrÃ£o de test_auto_capture.py)
```

---

### Passo 9: Atualizar DocumentaÃ§Ã£o

#### 9a. Atualizar `docs/futures/005_v1.0_duplicate_prevention.md`

Mudar status de `â³ Pendente` para `âœ… Completo`.

#### 9b. Atualizar `docs/futures/README.md`

Atualizar tabela de status da feature 005 para `âœ… Completo`.

---

## Resumo de Arquivos Afetados

| Arquivo | Tipo | DescriÃ§Ã£o |
|---------|------|-----------|
| `app/duplicate_prevention.py` | **NOVO** | MÃ³dulo de prevenÃ§Ã£o de duplicatas |
| `app/main.py` | Modificar | Import, `add_memory_trace_logic()` com check, MCP tool `remember` com `force`, endpoint `/check-duplicate`, Ã­ndice HNSW em `init_db()` |
| `app/rate_limiter.py` | Modificar | Adicionar mapping do endpoint `check-duplicate` |
| `migrations/002_duplicate_prevention.sql` | **NOVO** | Script de migraÃ§Ã£o para Ã­ndice vetorial |
| `tests/test_duplicate_prevention.py` | **NOVO** | Suite de testes (10 testes) |
| `docs/implementations/005_duplicate_prevention.md` | **NOVO** | Este documento (relatÃ³rio de implementaÃ§Ã£o) |
| `docs/futures/005_v1.0_duplicate_prevention.md` | Modificar | Atualizar status |
| `docs/futures/README.md` | Modificar | Atualizar tabela de status |

---

## Fluxo de Dados (Diagrama)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GravaÃ§Ã£o de MemÃ³ria                          â”‚
â”‚   MCP remember / REST chat / Auto-Capture                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              add_memory_trace_logic()                           â”‚
â”‚                                                                 â”‚
â”‚   1. embed_model.encode(content) â†’ vec (384-dim)               â”‚
â”‚   2. if not force:                                              â”‚
â”‚        check_duplicate(vec, owner_key, ...) â”€â”€â”                â”‚
â”‚        if is_duplicate:                        â”‚                â”‚
â”‚            merge_memory(existing_id) â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚            return {action: "merged"}                            â”‚
â”‚   3. INSERT INTO memories (... vec ...)                         â”‚
â”‚      return {action: "created"}                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       PostgreSQL                                â”‚
â”‚                                                                 â”‚
â”‚   memories table                                               â”‚
â”‚   â”œâ”€â”€ HNSW index (embedding vector_cosine_ops)                 â”‚
â”‚   â”œâ”€â”€ idx_memories_owner (owner_key)                           â”‚
â”‚   â””â”€â”€ idx_memories_workspace (owner_key, workspace)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Endpoint REST: Check Duplicate

```
POST /v1/memories/check-duplicate
```

### Request
```json
{
    "content": "Meu cafÃ© favorito Ã© cappuccino",
    "session_id": "default"
}
```

### Response (sem duplicata)
```json
{
    "is_duplicate": false,
    "existing_id": null,
    "existing_content": null,
    "similarity": 0.0
}
```

### Response (com duplicata)
```json
{
    "is_duplicate": true,
    "existing_id": 42,
    "existing_content": "[GENERAL] Meu cafÃ© favorito Ã© cappuccino",
    "similarity": 0.9823
}
```

---

## MCP Tool `remember` - Comportamento Atualizado

### Sem duplicata
```
Input:  remember(fact="Python 3.12 lanÃ§ado")
Output: "MemÃ³ria salva com sucesso na Nuvem Aethera."
```

### Com duplicata (default - merge)
```
Input:  remember(fact="Python 3.12 lanÃ§ado")
Output: "MemÃ³ria similar jÃ¡ existe (similaridade: 98.2%). Timestamp atualizado na memÃ³ria existente (ID: 42). Use force=true para gravar mesmo assim."
```

### Com force override
```
Input:  remember(fact="Python 3.12 lanÃ§ado", force=true)
Output: "MemÃ³ria salva com sucesso na Nuvem Aethera."
```

---

## Performance

### Custo da VerificaÃ§Ã£o

| OperaÃ§Ã£o | Tempo | Notas |
|----------|-------|-------|
| Embedding (jÃ¡ existente) | 0ms | Reaproveitado do fluxo normal |
| pgvector cosine search | ~5-15ms | Com Ã­ndice HNSW |
| Merge (UPDATE timestamp) | ~3-5ms | OperaÃ§Ã£o simples |
| **Overhead total** | **~5-15ms** | Apenas 1 query adicional |

### Sem Ãndice vs Com Ãndice

| CenÃ¡rio | Sem Ã­ndice | Com HNSW |
|---------|-----------|----------|
| 100 memÃ³rias | ~2ms | ~2ms |
| 10.000 memÃ³rias | ~50ms | ~5ms |
| 100.000 memÃ³rias | ~500ms | ~10ms |

---

## SeguranÃ§a

- **Multi-tenancy**: `check_duplicate` filtra por `owner_key` - um usuÃ¡rio nunca vÃª memÃ³rias de outro
- **SQL Injection**: Todas queries usam parameterized queries (`%s`)
- **Fail-open**: Em caso de erro no check, a memÃ³ria Ã© gravada normalmente (nÃ£o bloqueia funcionalidade)
- **Rate limiting**: Endpoint `/check-duplicate` Ã© rate-limited como `ACTION_EMBEDDING`

---

## Rollback

### CÃ³digo
```bash
git revert <commit-hash>
```

### Database
```sql
DROP INDEX IF EXISTS idx_memories_embedding_hnsw;
```

Nenhuma alteraÃ§Ã£o de schema nas tabelas existentes - apenas adiÃ§Ã£o de Ã­ndice.

---

## Ordem de ImplementaÃ§Ã£o (Sequencial)

1. **`app/duplicate_prevention.py`** - MÃ³dulo novo (sem dependÃªncias)
2. **`app/main.py`** - Import + modificar `add_memory_trace_logic()` + `init_db()` + MCP tool + endpoint
3. **`app/rate_limiter.py`** - Adicionar mapping do endpoint
4. **`migrations/002_duplicate_prevention.sql`** - Script de migraÃ§Ã£o
5. **`tests/test_duplicate_prevention.py`** - Suite de testes
6. **DocumentaÃ§Ã£o** - Atualizar specs e READMEs

---

## Checklist Final

- [ ] `app/duplicate_prevention.py` criado com `check_duplicate()` e `merge_memory()`
- [ ] `add_memory_trace_logic()` integrado com verificaÃ§Ã£o de duplicatas
- [ ] ParÃ¢metro `force: bool` adicionado em todos os caminhos de escrita
- [ ] MCP tool `remember` atualizada com `force` e mensagem de duplicata
- [ ] Endpoint `POST /v1/memories/check-duplicate` implementado
- [ ] Ãndice HNSW criado em `init_db()` e em migration script
- [ ] Rate limiter atualizado com novo endpoint
- [ ] 10 testes escritos e passando
- [ ] DocumentaÃ§Ã£o atualizada (spec + README)

---

**Versao do documento:** 1.0
**Ultima atualizacao:** 2026-02-10
